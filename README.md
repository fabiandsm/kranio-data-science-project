# ğŸš€ Retail Sales Prediction --- End-to-End ML Project

Proyecto completo de Ciencia de Datos y MLOps que implementa un flujo
end-to-end para predicciÃ³n de ventas futuras de clientes retail,
incluyendo:

âœ” ExploraciÃ³n de datos (EDA)\
âœ” IngenierÃ­a de variables\
âœ” Entrenamiento de modelo ML\
âœ” API de predicciÃ³n con FastAPI\
âœ” ContenerizaciÃ³n con Docker\
âœ” Preparado para automatizaciÃ³n con Airflow

Este proyecto demuestra habilidades prÃ¡cticas en:

-   Data Science
-   Machine Learning
-   Data Engineering
-   API deployment
-   Arquitectura de pipelines de datos

------------------------------------------------------------------------

## ğŸ“Š Flujo del proyecto

    Datos crudos
          â†“
    EDA
          â†“
    Feature Engineering
          â†“
    Entrenamiento modelo
          â†“
    Modelo guardado
          â†“
    API FastAPI
          â†“
    Docker
          â†“
    Pipeline automÃ¡tico (Airflow)

------------------------------------------------------------------------

## ğŸ“ Estructura del proyecto

    kranio-data-science-project/
    â”‚
    â”œâ”€â”€ data/                    # Datos de entrada
    â”œâ”€â”€ notebooks/
    â”‚   â”œâ”€â”€ 01_eda_retail_sales.ipynb
    â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
    â”‚   â””â”€â”€ 03_model_training.ipynb
    â”‚
    â”œâ”€â”€ outputs/
    â”‚   â””â”€â”€ models/
    â”‚       â””â”€â”€ retail_model.joblib
    â”‚
    â”œâ”€â”€ src/
    â”‚   â””â”€â”€ api.py               # API de predicciÃ³n
    â”‚
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ requirements-api.txt
    â””â”€â”€ README.md

------------------------------------------------------------------------

## ğŸ§  Modelo utilizado

Se entrenÃ³ un modelo de Machine Learning para estimar:

    Ventas futuras de clientes

Utilizando variables como:

-   Edad
-   Ingreso
-   Frecuencia de compra
-   Ticket promedio
-   Recencia de compra
-   Ratio online
-   Engagement del cliente
-   Score digital y actividad

------------------------------------------------------------------------

## âš™ï¸ Ejecutar API localmente

Instalar dependencias:

``` bash
pip install -r requirements-api.txt
```

Ejecutar API:

``` bash
uvicorn src.api:app --reload
```

DocumentaciÃ³n automÃ¡tica:

    http://127.0.0.1:8000/docs

------------------------------------------------------------------------

## ğŸ³ Ejecutar con Docker

Construir imagen:

``` bash
docker build -t retail-ml-api .
```

Ejecutar contenedor:

``` bash
docker run -p 8000:8000 retail-ml-api
```

------------------------------------------------------------------------

## ğŸ“ˆ PrÃ³ximo paso

AutomatizaciÃ³n completa con:

    Airflow pipeline

PermitirÃ¡:

-   Procesar nuevos datos
-   Generar features
-   Reentrenar modelo
-   Actualizar API automÃ¡ticamente

------------------------------------------------------------------------

## ğŸ‘¤ Autor

**FabiÃ¡n DÃ­az**\
Data Scientist \| Data Engineer \| Analytics Engineer
